{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02ac0c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717fe2db",
   "metadata": {},
   "source": [
    "# Loading consolidated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3a19196",
   "metadata": {},
   "outputs": [],
   "source": [
    "userprofile = pd.read_csv('WeightLoss/userprofile.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53085b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#can_record_consolidated = pd.read_csv('WeightLoss/can_record_consolidated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f32ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#comment_consolidated = pd.read_csv('WeightLoss/comment_consolidated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8b41a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mention_consolidated = pd.read_csv('WeightLoss/mention_consolidated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4fe7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#post_consolidated = pd.read_csv('WeightLoss/post_consolidated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa6a01ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_consolidated = pd.read_csv('WeightLoss/users_consolidated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62410165",
   "metadata": {},
   "outputs": [],
   "source": [
    "#weight_record_consolidated = pd.read_csv('WeightLoss/weight_record_consolidated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fcb48ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12338632\n"
     ]
    }
   ],
   "source": [
    "print(userprofile[\"user_id\"].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709999f2",
   "metadata": {},
   "source": [
    "# Loading networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cda7fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "friend_consolidated = pd.read_csv('WeightLoss/network/friend_consolidated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "268241be",
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_rela = pd.read_csv('WeightLoss/network/comment_rela.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5cc879ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "mention_rela = pd.read_csv('WeightLoss/network/mention_rela.csv')\n",
    "mention_rela.dropna(subset=['who-mention'], inplace=True) # remove rows with NaN in 'who-mention'\n",
    "mention_rela['who-mention'] = mention_rela['who-mention'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a2cc166b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         who-mention  mention-who              type   type-id  \\\n",
      "0                121           33     Mention::Post        11   \n",
      "1                121          143     Mention::Post        26   \n",
      "2                121          143     Mention::Post        27   \n",
      "3                121          121     Mention::Post        42   \n",
      "4                121           33  Mention::Comment         3   \n",
      "...              ...          ...               ...       ...   \n",
      "6502773      7796031      5683623  Mention::Comment  38734963   \n",
      "6502774      4917321      7190027  Mention::Comment  38734966   \n",
      "6502775     11719132     11939872  Mention::Comment  38734971   \n",
      "6502776     11998946     12252269  Mention::Comment  38734973   \n",
      "6502777     10125396      4156327  Mention::Comment  38734979   \n",
      "\n",
      "                  post-id   post-user        date  \n",
      "0              Post_ID:11       121.0  2013-09-30  \n",
      "1              Post_ID:26       121.0  2013-10-01  \n",
      "2              Post_ID:27       121.0  2013-10-01  \n",
      "3              Post_ID:42       121.0  2013-10-08  \n",
      "4              Post_ID:50       121.0  2013-10-14  \n",
      "...                   ...         ...         ...  \n",
      "6502773  Post_ID:19321237   7796031.0  2015-05-20  \n",
      "6502774  Post_ID:19329650   4917321.0  2015-05-20  \n",
      "6502775  Post_ID:19328736  11719132.0  2015-05-20  \n",
      "6502776  Post_ID:19259395  11998946.0  2015-05-20  \n",
      "6502777  Post_ID:19329743  10125396.0  2015-05-20  \n",
      "\n",
      "[6502742 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "print(mention_rela)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076be264",
   "metadata": {},
   "source": [
    "# Working with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7d67330",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e0bc714c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iteratively filters out low degree nodes from a graph\n",
    "# returns list of nodes of degree at least d\n",
    "# **note this runs out of memory if run directly on friend_net, would need an iterative solution maybe\n",
    "def filter_low_degree_nodes(graph, d=5):\n",
    "    # get the nodes and their degrees\n",
    "    included_nodes, degrees = torch.unique(graph.edge_index[0], return_counts=True)\n",
    "    print(\"Current Size:\", included_nodes.shape)\n",
    "    # generate a mask that is True for degrees >= d and False otherwise\n",
    "    filter_mask = torch.ge(degrees,d)\n",
    "    if(torch.unique(filter_mask).shape[0] != 1): # check that the mask still contains both True and False, otherwise done\n",
    "        # filter the nodes based on the mask\n",
    "        filtered_nodes = torch.masked_select(included_nodes,filter_mask)\n",
    "        # generate the subgraph on the filtered nodes\n",
    "        subgraph = graph.subgraph(filtered_nodes)\n",
    "        # recursive call: now filter again based on the new subgraph\n",
    "        # returns indices on what was passed in\n",
    "        subgraph_nodes = filter_low_degree_nodes(subgraph)\n",
    "        # convert back to original node names\n",
    "        included_nodes = filtered_nodes[subgraph_nodes]\n",
    "    # return the new included_nodes\n",
    "    return included_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "27172a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes = userprofile[\"user_id\"].max() # max id\n",
    "\n",
    "# convert data to appropriate form and generate a PyG graph\n",
    "friend_edge_index = torch.from_numpy(friend_consolidated.iloc[:,[0,1]].to_numpy())\n",
    "friend_net = Data(edge_index=friend_edge_index.t().contiguous())\n",
    "friend_net.num_nodes = num_nodes\n",
    "\n",
    "comment_edge_index = torch.from_numpy(comment_rela.iloc[:,[0,1]].to_numpy())\n",
    "comment_net = Data(edge_index=comment_edge_index.t().contiguous())\n",
    "comment_net.num_nodes = num_nodes\n",
    "\n",
    "mention_edge_index = torch.from_numpy(mention_rela.iloc[:,[0,1]].to_numpy())\n",
    "mention_net = Data(edge_index=mention_edge_index.t().contiguous())\n",
    "mention_net.num_nodes = num_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9a3b0ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering on comment_net:\n",
      "Current Size: torch.Size([498705])\n",
      "Current Size: torch.Size([162621])\n",
      "Current Size: torch.Size([158370])\n",
      "Current Size: torch.Size([158219])\n",
      "Current Size: torch.Size([158214])\n",
      "Current Size: torch.Size([158213])\n",
      "Nodes after filter on comment net: tensor([       3,        4,       10,  ..., 12325382, 12325432, 12325695])\n",
      "Filtering on mention_net:\n",
      "Current Size: torch.Size([116365])\n",
      "Current Size: torch.Size([70191])\n",
      "Current Size: torch.Size([62368])\n",
      "Current Size: torch.Size([61242])\n",
      "Current Size: torch.Size([61036])\n",
      "Current Size: torch.Size([60998])\n",
      "Current Size: torch.Size([60987])\n",
      "Current Size: torch.Size([60985])\n",
      "Current Size: torch.Size([60984])\n",
      "Nodes after filter on mention net: tensor([      10,       27,       31,  ..., 12275466, 12288211, 12309780])\n",
      "Filtering on friend_net:\n",
      "Current Size: torch.Size([56413])\n",
      "Current Size: torch.Size([40258])\n",
      "Current Size: torch.Size([38691])\n",
      "Current Size: torch.Size([38470])\n",
      "Current Size: torch.Size([38440])\n",
      "Current Size: torch.Size([38436])\n",
      "Final nodes: tensor([      10,       27,       31,  ..., 11889042, 11890543, 11923113])\n"
     ]
    }
   ],
   "source": [
    "# filter out the low degree nodes\n",
    "print(\"Filtering on comment_net:\")\n",
    "nodes_after_filter_on_comment_net = filter_low_degree_nodes(comment_net)\n",
    "print(\"Nodes after filter on comment net:\", nodes_after_filter_on_comment_net)\n",
    "print(\"Filtering on mention_net:\")\n",
    "mention_sub_net = mention_net.subgraph(nodes_after_filter_on_comment_net)\n",
    "nodes_after_filter_on_mention_net = nodes_after_filter_on_comment_net[filter_low_degree_nodes(mention_sub_net)]\n",
    "print(\"Nodes after filter on mention net:\", nodes_after_filter_on_mention_net)\n",
    "print(\"Filtering on friend_net:\")\n",
    "friend_sub_net = friend_net.subgraph(nodes_after_filter_on_mention_net)\n",
    "final_nodes = nodes_after_filter_on_mention_net[filter_low_degree_nodes(friend_sub_net)]\n",
    "print(\"Final nodes:\", final_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6134295f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get final networks\n",
    "final_friend_net = friend_net.subgraph(final_nodes)\n",
    "final_comment_net = comment_net.subgraph(final_nodes)\n",
    "final_mention_net = mention_net.subgraph(final_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3418f9c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([    1,     2,     3,  ..., 18890, 19411, 24730]) tensor([ 56, 148, 312,  ...,   1,   1,   1])\n"
     ]
    }
   ],
   "source": [
    "# checker\n",
    "nodes, degs = torch.unique(final_mention_net.edge_index[0], return_counts=True)\n",
    "unique_degs,counts = torch.unique(degs, return_counts=True)\n",
    "print(unique_degs, counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2041a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b667c8a5",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29725867",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = torch.tensor([[0, 1, 2, 1,0],\n",
    "                           [1, 0, 1, 2,2]], dtype=torch.long)\n",
    "x = torch.tensor([[-1], [0], [1]], dtype=torch.float)\n",
    "\n",
    "data = Data(x=x, edge_index=edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08da2a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "deg = degree(data.edge_index[0], data.num_nodes)\n",
    "print(deg[2])  # degree of node 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdbbb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "subs = torch.tensor([2,0])\n",
    "sub = data.subgraph(subs)\n",
    "print(sub)\n",
    "print(sub.edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d351e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "deg = degree(sub.edge_index[0], sub.num_nodes)\n",
    "print(deg[1])  # degree of node 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304f7a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([3,2,0])\n",
    "b = torch.tensor([0,2])\n",
    "\n",
    "print(a[b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943a7cb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9a8347",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b4850c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5421c1a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch-G]",
   "language": "python",
   "name": "conda-env-pytorch-G-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
